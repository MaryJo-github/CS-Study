# 메모리 계층

- 레지스터, 캐시, 메모리, 저장장치로 구성됨 (속도 ⬅️, 용량 ➡️)
    - 레지스터
        - CPU 안에 있는 작은 메모리
        - 휘발성, 속도 가장 빠름, 기억 용량 가장 적음
    - 캐시
        - 보통 L1, L2 캐시를 지칭, L3 캐시도 있음
        - 휘발성, 속도 빠름, 기억 용량 적음
    - 주기억장치
        - RAM
        - 휘발성, 속도 보통, 기억 용량 보통
    - 보조기억장치
        - HDD, SSD
        - 비휘발성, 속도 낮음, 기억 용량 많음
- RAM은 하드디스크로부터 일정량의 데이터를 복사해서 임시 저장하고 이를 필요 시마다 CPU에 빠르게 전달하는 역할.
- 계층이 올라갈 수록 가격은 비싸지고 용량은 작아짐. 속도는 빨라짐.

## 캐시

- 데이터를 미리 복사해 놓는 임시 저장소
- 빠른 장치와 느린 장치에서 속도 차이에 따른 병목현상을 줄이기 위한 메모리
- 데이터를 접근하는 시간이 오래 걸리는 경우를 해결하고 반복 계산하는 시간을 절약
- ex. 메모리와 CPU사이의 속도차이를 줄이기 위해 중간에 레지스터 계층을 둬서 속도 차이를 해결
    - 속도 차이를 해결하기 위해 계층과 계층 사이에 있는 계층을 **캐싱 계층**이라고 함
    - 캐시 메모리와 보조기억장치 사이에 있는 주기억장치를 보조기억장치의 캐싱 계층이라고 할 수 있음
- 캐시 직접 설정
    - 자주 사용하는 데이터를 기반으로 설정. 근거는 지역성
    - 시간 지역성(temporal locality)
        - 최근 사용한 데이터에 다시 접근하려는 특성
    - 공간 지역성(spatial locality)
        - 최근 접근한 데이터를 이루고 있는 공간이나 그 가까운 공간에 접근하는 특성

## 캐시히트와 캐시미스

- 캐시히트
    - 캐시에서 원하는 데이터를 찾았다면 캐시 히트
    - 해당 데이터를 제어장치를 거쳐 가져오게 됨
    - 위치도 가깝고 CPU 내부 버스를 기반으로 작동하기 때문에 빠름
- 캐시미스
    - 데이터에 캐시가 없다면 주 메모리로 가서 데이터를 찾아오는 것을 캐시미스
    - 시스템 버스를 기반으로 작동하기 때문에 느림
- 캐시매핑
    - 캐시가 히트되기 위해 매핑하는 방법
    - ex. CPU의 레지스터와 주 메모리(RAM) 간에 데이터를 주고받을 때,
    레지스터는 주 메모리에 비해 용량이 작기 때문에 캐시 계층으로써 역할을 잘 해주려면 매핑을 어떻게 하느냐가 중요
    - 캐시매핑 분류
        
        
        | 이름 | 설명 |
        | --- | --- |
        | 직접 매핑(directed mapping) | 메모리가 1~100이 있고 캐시가 1~10이 있다면 1:1~10, 2:1~20 으로 매핑. 처리가 빠르지만 충돌 발생이 잦음 |
        | 연관 매핑(associative mapping) | 순서와 관계없이 관련 있는 캐시와 메모리를 매핑. 충돌이 적지만 모든 블록을 탐색해야 해서 속도가 느림 |
        | 집합 연관 매핑(set associative mapping) | 직접 매핑 + 연관 매핑. 순서는 일치시키지만 집합을 둬서 저장. 검색은 좀 더 효율적. 메모리 1~100, 캐시 1~10이 있다면 캐시 1~5에는 1~50의 데이터를 무작위로 저장시키는 것 |
- 웹 브라우저의 캐시
    - 대표적으로 작은 저장소 쿠키, 로컬 스토리지, 세션 스토리지가 있음
        - 쿠키: 만료기한이 있는 키-값 저장소.
        - 로컬 스토리지: 만료기한이 없는 키-값 저장소. 웹 브라우저를 닫아도 유지됨.
        - 세션 스토리지: 만료기한이 없는 키-값 저장소. 탭 단위로 세션 스토리지를 생성하며, 탭을 닫을 때 해당 데이터가 삭제됨.
    - 보통 사용자의 커스텀한 정보나 인증 모듈 관련 사항들을 웹 브라우저에 저장해서 추후 서버에 요청할 때 아이덴티티나 중복 요청 방지를 위해 쓰이며 오리진에 종속됨
- 데이터베이스의 캐싱 계층
    - 메인 데이터베이스 위에 레디스(redis) 데이터베이스 계층을 캐싱 계층으로 둬서 성능을 향상시키기도 함

# 메모리 관리

## 가상 메모리 (virtual memory)

- 하나의 컴퓨터가 실제로 이용 가능한 메모리 자원을 추상화하여 이를 사용하는 사용자들에게 매우 큰 메모리로 보이게 만드는 메모리 관리 기법
- 가상적으로 주어진 주소를 가상 주소(logical address), 실제 메모리상에 있는 주소를 실제 주소(physical address)라고 함
- 가상 주소는 메모리관리장치(MMU)에 의해 실제 주소로 변환되기 때문에 사용자는 실제 주소를 의식하지 않아도 됨
- 스와핑 (swapping)
    - 만약 가상 메모리에는 존재하지만 실제 메모리인 RAM에는 현재 없는 데이터나 코드에 접근할 경우 페이지 폴트가 발생
    - 이 때 메모리에서 당장 사용하지 않는 영역을 하드디스크로 옮기고 하드디스크의 일부분을 마치 메모리처럼 불러와 쓰는 것을 스와핑이라고 함
    - 이를 통해 마치 페이지 폴트가 일어나지 않은 것처럼 만듦
        - 페이지 폴트: 프로세스의 주소 공간에는 존재하지만 RAM에는 없는 데이터에 접근했을 경우에 발생.
        1. 어떤 명령어가 유효한 가상 주소에 접근했으나 해당 페이지가 만약 없다면 트랩이 발생되어 운영체제에 알림
        2. 운영체제는 실제 디스크로부터 사용하지 않은 프레임을 찾음
        3. 해당 프레임을 실제 메모리에 가져와서 페이지 교체 알고리즘을 기반으로 특정 페이지와 교체
        4. 페이지 테이블을 갱신시킨 후 해당 명령어를 다시 시작
            - 페이지(page): 가상 메모리를 사용하는 최소 크기 단위
            - 프레임(frame): 실제 메모리를 사용하는 최소 크기 단위

## 스레싱 (thrashing)

- 메모리의 페이지 폴트율이 높은 것 → 컴퓨터의 심각한 성능 저하 초래
- 메모리에 너무 많은 프로세스가 동시에 올라가게 되면 스와핑이 많이 일어남 → 페이지 폴트가 일어나면 CPU 이용률이 낮아짐 → CPU가 한가하다고 생각하여 더 많은 프로세스를 메모리에 올림 (악순환)
- 해결 방법
    - 메모리를 늘리기
    - HDD를 사용한다면 SSD로 바꾸기
    - 운영체제에서 해결할 수 있는 방법은 작업 세트와 PFF가 있음
        - 작업 세트: 프로세스의 과거 사용 이력인 지역성을 통해 결정된 페이지 집합을 만들어서 미리 메모리에 로드하는 것. → 탐색에 드는 비용을 줄일 수 있고 스와핑도 줄일 수 있음
        - PFF(Page Fault Frequency): 페이지 폴트 빈도의 상한선과 하한선을 만듦. 상한선에 도달한다면 프레임을 늘리고, 하한선에 도달한다면 프레임을 줄임.

## 메모리 할당

- 메모리에 프로그램을 할당할 때에는 시작 메모리 위치, 메모리의 할당 크기를 기반으로 할당하는데, 연속 할당과 불연속 할당이 있음
- 연속 할당
    - 프로세스를 순차적으로 공간에 할당하는 것
    - 고정 분할 방식과 가변 분할 방식이 있음
        - 고정 분할 방식: 메모리를 미리 나누어 관리하는 방식. 메모리가 미리 나뉘어 있기 때문에 융통성이 없고, 내부 단편화가 발생
        - 가변 분할 방식: 매 시점 프로그램의 크기에 맞게 동적으로 메모리를 나눠서 사용. 내부 단편화는 발생하지 않고 외부 단편화는 발생할 수 있음.
            - 가변 분할 방식 종류
                
                
                | 이름 | 설명 |
                | --- | --- |
                | 최초적합 | 위쪽이나 아래쪽부터 시작해서 홀을 찾으면 바로 할당 |
                | 최적적합 | 프로세스의 크기 이상인 공간 중 가장 작은 홀부터 할당 |
                | 최악적합 | 프로세스의 크기와 가장 많이 차이가 나는 홀에 할당 |
- 불연속 할당
    - 현대 운영체제가 쓰는 방법
    - 페이징 기법, 세그멘테이션, 페이지드 세그멘테이션이 있음
        - 페이징: 동일한 크기의 페이지(보통 4KB)로 나누어 메모리의 서로 다른 위치에 프로세스를 할당. 홀의 크기가 균일하지 않은 문제가 없어지지만 주소 변환이 복잡해짐.
        - 세그멘테이션: 페이지 단위가 아닌 의미 단위인 세그먼트로 나누는 방식. 프로세스를 이루는 메모리는 코드 영역, 데이터 영역, 스택 영역, 힙 영역으로 이루어지는데, 코드와 데이터로 나누거나 코드 내의 작은 함수를 세그먼트로 놓고 나눌 수도 있음. 공유와 보안 측면에서 장점을 가지지만 홀 크기가 균일하지 않은 단점이 있음.
        - 페이지드 세그멘테이션: 프로그램을 의미 단위인 세그먼트로 나눠 임의의 길이가 아닌 동일한 크기의 페이지 단위로 나누는 것. 공유나 보안 측면에서 장점을 가짐.

## 페이지 교체 알고리즘

- 페이지 교체 알고리즘을 기반으로 스와핑이 일어남
- 오프라인 알고리즘
    - 다른 알고리즘과의 성능 비교에 대한 기준을 제공하기 위한 방법
    - 먼 미래에 참조되는 페이지와 현재 할당하는 페이지를 바꾸는 알고리즘
    - 사용할 수 없는 알고리즘이지만 가장 좋은 알고리즘
- FIFO (First In First Out)
    - 가장 먼저 온 페이지를 교체 영역에 가장 먼저 놓는 방법
- LRU (Least Recently Used)
    - 참조가 가장 오래된 페이지를 교체
    - 오래된 것을 파악하기 위해 각 페이지마다 계수기, 스택을 두어야 하는 단점 존재
- LFU (Least Frequently Used)
    - 참조 횟수가 가장 적은 페이지를 교체
